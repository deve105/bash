{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources\n",
    " * https://github.com/niemasd/ViralConsensus\n",
    " * https://hpc.nih.gov/apps/trimAl.html\n",
    " * http://www.iqtree.org/doc/Dating\n",
    " * https://en.wikipedia.org/wiki/Ancestral_reconstruction\n",
    " * https://bootstrappers.umassmed.edu/bootstrappers-courses/courses/rCourse/\n",
    " * https://bookdown.org/pdr_higgins/rmrwr/\n",
    " * https://rmarkdown.rstudio.com/lesson-2.html\n",
    " * https://www.markdownguide.org/cheat-sheet/\n",
    " * https://learnmetabarcoding.github.io/LearnMetabarcoding/gettingstarted/cli_bioinformatics/cheatsheet.html\n",
    " * https://evol.bio.lmu.de/_statgen/compevol/PhyloHandout.pdf\n",
    " * https://viralzone.expasy.org/5576\n",
    " * https://www.biostars.org/p/418165/\n",
    " * https://github.com/inab/trimal\n",
    " * https://jlsteenwyk.com/ClipKIT/other_software/index.html\n",
    " * https://phyluce.readthedocs.io/en/latest/daily-use/daily-use-3-uce-processing.html\n",
    " * https://astrobiomike.github.io/genomics/phylogenomics\n",
    " * https://github.com/mmatschiner/tutorials\n",
    " * https://yulab-smu.top/treedata-book/index.html\n",
    " * https://jvanheld.github.io/using_IFB_NNCR/practicals/blast_proteome/blast_proteome.html\n",
    "https://treetime.readthedocs.io/en/latest/tutorials/timetree.html\n",
    "https://academic.oup.com/ve/article/4/1/vex042/4794731?login=true\n",
    "https://github.com/neherlab/treetime_examples/blob/master/data/ebola/ebola.metadata.csv\n",
    "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5860581/\n",
    "https://hal.science/hal-01334934/document\n",
    "https://taming-the-beast.org/tutorials/FBD-tutorial/FBD-tutorial.pdf\n",
    "https://cran.r-project.org/web/packages/Rphylopars/Rphylopars.pdf\n",
    "https://yulab-smu.top/treedata-book/chapter1.html\n",
    "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6294524/\n",
    "http://www.iqtree.org/doc/iqtree-doc.pdf\n",
    "https://hal.science/hal-01334934/document\n",
    "https://en.wikipedia.org/wiki/Ancestral_reconstruction\n",
    "\n",
    "* https://treetime.readthedocs.io/en/latest/tutorials/timetree.html\n",
    "https://academic.oup.com/ve/article/4/1/vex042/4794731?login=true\n",
    "https://github.com/neherlab/treetime_examples/blob/master/data/ebola/ebola.metadata.csv\n",
    "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5860581/\n",
    "https://hal.science/hal-01334934/document\n",
    "https://taming-the-beast.org/tutorials/FBD-tutorial/FBD-tutorial.pdf\n",
    "https://cran.r-project.org/web/packages/Rphylopars/Rphylopars.pdf\n",
    "https://yulab-smu.top/treedata-book/chapter1.html\n",
    "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6294524/\n",
    "http://www.iqtree.org/doc/iqtree-doc.pdf\n",
    "https://hal.science/hal-01334934/document\n",
    "  * https://en.wikipedia.org/wiki/Ancestral_reconstruction\n",
    "\n",
    "  * https://github.com/phac-nml/refseq_masher  #In case that you need to know what genomes are included in your sample \n",
    "\n",
    "    https://github.com/amkozlov/raxml-ng\n",
    "\n",
    "    https://hal.science/hal-02535311/document\n",
    "\n",
    "\n",
    "https://nbisweden.github.io/workshop-plotting-in-r/2109/lab_phylo.html\n",
    "https://yulab-smu.top/treedata-book/chapter5.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consensus sequences (September-2023)\n",
    "Samples were obtained from the HTLV-1 cohort of the Instituto de Medicina Tropical Alexander Von Humboldt (Lima-Peru) and the protocol was approved by the institutional board review at the Universidad Cayetano Heredia (Lima-Peru)\n",
    "Purified DNA\n",
    "sequenced on a Illumina Hiseq3000 at a depth of .... (place were)\n",
    "\n",
    "The sequences were obtained using Hiseq3000, quality and adaptor removal was done with fastp.\n",
    "reads were analized using consensus calling BWA MEM + IVAR and J02029.1 as reference sequence, using t 0.8 and quality parameter pileup 20 in samstool.\n",
    "Raw FASTQ files were read using two approaches:\n",
    "\n",
    "#### 11-24 writing: Methods (peru primary samples)\n",
    "\n",
    "IVAR sequences were analyzed as gold standar  (initial file with 71)\n",
    " less than 6000 bp excluded IRID011_S130, IRID038_S122, IRID040_S124, IRID067_S233, JP_14_S84, JP_17_S87\n",
    "\n",
    "duplicated sequences IRID025_S236 y IRID026_S237 (IRID026 was eliminated)\n",
    "76 sequences remained for further analysis\n",
    "pairwise identity >60%\n",
    "\n",
    "\n",
    "\n",
    "MSA -> MAFFT\n",
    "maximum likelihood inference RAxML-NG\n",
    "\n",
    "#### alignment them\n",
    "*L-INS-i (probably most accurate; recommended for <200 sequences; iterative refinement method incorporating local pairwise alignment information):\n",
    "\n",
    "delted first 22 and last 13 nucleotides manually considered too gappy\n",
    "https://mafft.cbrc.jp/alignment/software/manual/manual.html\n",
    "\n",
    "### 09-06 Previamente incomplete sequences:\n",
    "\n",
    ">PE_SS02_S1 eliminated, Peru_IRID062_S231 remains\n",
    ">PE_SS04_S3 eliminated, Peru_IRID039_S123 remains\n",
    ">PE_SS20_S204 eliminated, Peru_IRID089_S292 remains\n",
    "IRID032_S117\n",
    "\n",
    "iqtree2 -s 0923gp46all_2020liao.fa -m TN+F+I+R3 -B 10000 -alrt 10000 --polytomy  -blmin 3.3e-7 -T 5  -mem 20G --prefix iqtree1002_\n",
    "notes\"\n",
    "\n",
    "were excluded for being too gapy\n",
    "M86840.1\n",
    "NC_001436.1\n",
    "\n",
    "awk 'BEGIN {i = 1;} { if ($1 ~ /^>/) { tmp = h[i]; h[i] = $1; } else if (!a[$1]) { s[i] = $1; a[$1] = \"1\"; i++; } else { h[i] = tmp; } } END { for (j = 1; j < i; j++) { print h[j]; print s[j]; } }' < in.fa > out.fa\n",
    "$ cat out.fa\n",
    "\n",
    "#using aliview i checked Duplicates\n",
    "LC209998.1 (remains LC210057.1)\n",
    "LC210056.1\n",
    "LC210015.1\n",
    "#using aliview to merge all samples (NCBI + Peru x3a)\n",
    "4seqcghtlv0906all.fa\n",
    "No duplicates found\n",
    "#create a final list\n",
    "grep -e \">\" my.fasta > 4listseqcg\n",
    "#without >\n",
    "sed 's/>//g' 4listseqcg > 4listfin\n",
    "\n",
    "\n",
    "## make a list of accesion numbers\n",
    "seq -f \"MT113%g\" 123 153 > 2020liao.txt\n",
    "seq -f \"MT113%g\" 155 178 >> 2020liao.txt \n",
    "while read line;\n",
    "do\n",
    "$line;\n",
    "done <\n",
    "oartition 1-759 ()\n",
    "5187-6653\n",
    "5203..6669 (NCBI)\n",
    "DNA, part1 = 1-759\n",
    "DNA, part2 = 5187-6653\n",
    "gp46 = 5015-\n",
    "gp46 = 5187-6129"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# three folders were analized 181215_Hiseq3000  460 181225_Hiseq3000  689 190104_Hiseq3000\n",
    "#a folder with all reads R1 and R3 were reads\n",
    "# Mode 01 using BWA MEM + IVAR\n",
    "for i in $(ls -1 *R1_001.fastq.gz | sed 's/\\R1_001.fastq.gz//'); do \n",
    "    f1=Peru_$(echo $i | sed 's/.*Nakahata_//'| sed 's/_L00._//') #definition of f1\n",
    "    echo \"$i\"\"->\"\"$f1\" #print message\n",
    "    #first FASTP for quality\n",
    "    fastp -i ${i}\\R1_001.fastq.gz -I ${i}\\R3_001.fastq.gz -o ~/projects/seq0914/${f1}\\_R1.fastq.gz -O ~/projects/seq0914/${f1}\\_R2.fastq.gz\n",
    "    #second obtain the bam file\n",
    "    bwa mem -t 5 ~/projects/rawseq0824/J2029/J02029.1.fasta ~/projects/seq0914/${f1}\\_R1.fastq.gz ~/projects/seq0914/${f1}\\_R2.fastq.gz | \n",
    "    samtools --threads 5 sort  -o ~/projects/seq0914/$f1\\.bam\n",
    "    #third, pileup using Q20 and ivar -t 0.8\n",
    "    samtools mpileup -aa -A -d 1000000 -Q 20 ~/projects/seq0914/$f1\\.bam | \n",
    "    ivar consensus -t .8 -m 10 -p  ~/projects/seq0914/fasta/$f1\\.fa\n",
    "    rm ~/projects/seq0915/$f1\\.bam ~/projects/seq0915/${f1}\\_R1.fastq.gz ~/projects/seq0915/${f1}\\_R2.fastq.gz; done\n",
    "\n",
    "\n",
    "#Mode 02 using minimap2 + viral_consensus\n",
    "for i in $(ls -1 *R1_001.fastq.gz | sed 's/\\R1_001.fastq.gz//'); do \n",
    "    f1=Peru_$(echo $i | sed 's/.*Nakahata_//'| sed 's/_L00._//')\n",
    "    echo \"$i\"\"->\"\"$f1\"\n",
    "    #first FASTP for quality    \n",
    "    fastp -i ${i}\\R1_001.fastq.gz -I ${i}\\R3_001.fastq.gz -o ~/projects/seq0915/${f1}\\_R1.fastq.gz -O ~/projects/seq0915/${f1}\\_R2.fastq.gz\n",
    "    minimap2 -t 5 -ax sr ~/projects/rawseq0824/J2029/J02029.1.fasta ~/projects/seq0915/${f1}\\_R1.fastq.gz  ~/projects/seq0915/${f1}\\_R2.fastq.gz |\n",
    "    viral_consensus -i - -r ~/projects/rawseq0824/J2029/J02029.1.fasta -o ~/projects/seq0915/fasta/$f1\\.fa; done\n",
    "\n",
    "#Mode 02 but with t 0.8 for next project about comparison\n",
    "for i in $(ls -1 *R1_001.fastq.gz | sed 's/\\R1_001.fastq.gz//'); do \n",
    "f1=Peru_$(echo $i | sed 's/.*Nakahata_//'| sed 's/_L00._//')\n",
    "path=/home/dev105/projects/seq0917\n",
    "echo \"$i\"\"->\"\"$f1\"\n",
    "fastp -i ${i}\\R1_001.fastq.gz -I ${i}\\R3_001.fastq.gz -o $path/${f1}\\_R1.fastq.gz -O $path/${f1}\\_R2.fastq.gz\n",
    "bwa mem -t 5 ~/projects/rawseq0824/J2029/J02029.1.fasta $path/${f1}\\_R1.fastq.gz $path/${f1}\\_R2.fastq.gz | samtools sort  -o $path/$f1\\.bam\n",
    "samtools mpileup -aa -A -d 1000000 -Q 20 $path/$f1\\.bam | ivar consensus -t .8 -m 10 -p  $path/fasta_ivar/$f1\\.fa\n",
    "minimap2 -t 5 -ax sr ~/projects/rawseq0824/J2029/J02029.1.fasta $path/${f1}\\_R1.fastq.gz  $path/${f1}\\_R2.fastq.gz | viral_consensus -i - -f 0.8 -r ~/projects/rawseq0824/J2029/J02029.1.fasta -o $path/fasta_vircons/$f1\\.fa\n",
    "rm $path/$f1\\.bam $path/${f1}\\_R1.fastq.gz  $path/${f1}\\_R2.fastq.gz ; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#Manipulating sequences\n",
    "ls -ltr | awk '/Japan.*fa/ {print \"mv \"$NF\" \"substr($NF,1,15)}'\n",
    "#to rename files\n",
    "for i in $(ls GCF*.gz); do var=$(echo $i | awk -F \"_\" '{print $1\"_\"$2}'); echo $var; mv $i $var; done\n",
    "for i in $(ls *.fa); do var=$(echo $i | awk -F \"_\" '{print \"Japan_\" $3 \"_\" $4}'); echo $var; mv $i $var; done\n",
    "for i in $(ls *.fa); do var=$(echo $i | awk -F \".\" '{print $1 \".fa\"}'); echo $var; mv $i $var; done\n",
    "#rename other folder\n",
    "ls Peru_*_IRID*.fa\n",
    "for i in $(ls Peru_*_IRID*.fa); do var=$(echo $i | awk -F \"_\" '{print $1 \"_\" $3 \"_\" $4}'); echo $var; mv $i $var; done\n",
    "#rename the header with file names\n",
    "for file in *.fa;    do        sed -i \"s/>.*/${file%%.*}/\" \"$file\" ; done\n",
    "sed -i \"s/Japan.*/^>./\" \n",
    "sed 's/Japan/\\>Japan\\_vircons/g'  japan0919vir_cons > japanvircons\n",
    "#Searching for gp46 in blast (ANOTHER PROJECT)\n",
    "#Some of the accessions provided ['AB273635.1', 'AJ493586.1', 'AJ493585.1', 'AJ493584.1', 'AJ493594.1', 'AJ493589.1', 'AJ493588.1', 'AJ493592.1', '70.74', 'M64607.1'] were not found\n",
    "datasets download virus genome accession --inputfile gp46_blast_0928.txt\n",
    "#delete repeated headers\n",
    "awk '/^>/ { f = !a[$0]++ } f' all_seq_maffted > all_seq_maffted_uniq\n",
    "#to rename multiple files in a folder txt -> pdf\n",
    "for a in *.txt; do mv -- \"$a\" \"${a%.txt}.pdf\"; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NCBI search\n",
    "Blast nucleotide and J02029.1 (accessed November 2023), using length filters for sequences larger than 6000 bp \n",
    "\n",
    "at novemeber 2023\n",
    "1. using blast nucleotide and J02029.1 as reference sequence with length filter between 6000 and 10000 bp (6000:10000[slen]) -> obtained 444 complete genome sequences\n",
    "2. Using blast for taxid 11908, HTLV-2,3 and STLV-1 sequences were excluded (328 samples)\n",
    "3. duplicates sequences, and sequences from cell lines were excluded (n=6, M86840.1, LC378575.1,  animal L03562.2\n",
    "animal L03561.2, cell D13784.1, cell AB979451.1 ) using seqkit (322 samples)\n",
    "4. metadata and genome sequences were obtained with datasets and dataformats in the command line on linux \n",
    "\n",
    "airwise identity >60%\n",
    "\n",
    "\n",
    "---\n",
    "### Dataset and sequence alignment\n",
    "A total of xx HTLV-1 sequences were downloaded from the GenBank in Septeber 2023.\n",
    "were query using J02029.1 (Accession number M33896) blastn, megablast, parameters (max target sequences 5000 and expected threshold 0.65)\n",
    "using as query sequence J02029.1  M33896\n",
    "\n",
    "Step 1. sequences shorter than 6000 bp were excluded, thus\n",
    "```{r flow}\n",
    "library(pacman)\n",
    "p_load(DiagrammeR())\n",
    "\n",
    "HTLV-1 length:\n",
    "\n",
    "\n",
    "Total Samples included: 391 but 10 were deleted (Miyazaki samples)\n",
    "01/15: 381 samples\n",
    "\n",
    "\n",
    "Partitions:\n",
    " + LTR: 1510 nucleotides\n",
    " + env: 489c\n",
    " + rest: 6056\n",
    "\n",
    "Tip dates:\n",
    "Tip locations:\n",
    "Site model:\n",
    " + For Partition LTR:(TIM2+F+R3)\n",
    " + For Partition env:(TPM3+I+R2)\n",
    " + For Partition rest_CG: TN+F+R3\n",
    "\n",
    "clock model, I am not sure if I should use an strict or relaxed clock.\n",
    " + LTR: 5.6 x10-7 \n",
    " + env:2.1 x10-7 \n",
    " + rest_CG: 3.44 x10-7 \n",
    "\n",
    "\n",
    "### Results\n",
    "x HTLV-1 infected Peruvian adults (xx women and yy men) were included in this study. The median age was yy years old [range xx-xx].xx individuals were from xxx, xx from and xx from. Almost all patients were asymptomatic carriers, also there xx were ATLaggresive indolent HAM/TSP abd.\n",
    "\n",
    "Phylogenetic analyses were performed based on three partitions LTR, env and rest of the genome\n",
    "% of the strains were classified as .\n",
    "\n",
    "\n",
    "### Methods\n",
    "Recombination analysis\n",
    "An exploratory screening for recombination was performed using phylogenetic methods (Bootscan and RDP), and nucleotide substitution methods (Chimaera, GENECONV, MaxChi, SisCan and 3Seq), Additionally phi-test performed in the RDP4.5 software. Sequences with potential recombination signal were considered when at least four alogorithms reached a threshold p-value of 0.05 with Bonferroni correction.\n",
    "GARD implemented in Hyphy was used to evaluate\n",
    "\n",
    "\n",
    "Population Structure characterization\n",
    "After spare samples with potential recombination signal\n",
    " a phylogene-free population genetics approach \n",
    "\n",
    " until the algorithm converged to a local optiom\n",
    " max depth and n.pop\n",
    "\n",
    " s of diferent hierarchical clustering and the initial cluster number respectively\n",
    "\n",
    " d using the log marginal\n",
    "likelihoods (logML) at each BAPS depth, representing\n",
    "a parameter for quality improving of inferences, as the\n",
    "lower logML means the higher genetic mixture. Te\n",
    "geographical diversity at the country/area level was\n",
    "assessed through Simpson index (SI) and Shannon–\n",
    "Wiener index (SWI) using R package ‘vegan’ by treating one country/area as an individual community unit.\n",
    "\n",
    "SI represents 0 to 1 probability belonging to the same\n",
    "species when two sampling from one community [49],\n",
    "with 0 representing no diversity and 1 infnite diversity.\n",
    "Meanwhile, SWI of diversity quantifes the uncertainty\n",
    "in the strings of text, with higher SWI meaning higher\n",
    "diversit\n",
    "\n",
    "model-based\n",
    "techniques with an initial fast distance-based complete-linkage\n",
    "agglomerative clustering\n",
    "” (Hierarchical Bayesian Analysis of Population Structure) v.1.1.0 phylogeny-free\n",
    "Bayesian clustering implemented in R (RhierBAPS) was used to evaluate  with three hierarchy levels with an upper limit of 20 clusters sets.\n",
    "\n",
    "groups identifed using a Bayesian\n",
    "clustering method (called as ‘BAPS groups’) tended to be composed\n",
    "of samples from the same continents\n",
    "\n",
    "Potential recombinant sequences were considered\n",
    "\n",
    "\n",
    "and GARD. \n",
    "in the final curated dataset using phi-testsBOOTSCAN.\n",
    "explroatory screening using RDP, GENECONV and MAXCHI and Phi test implemented in RDP 5.\n",
    "no evidence of recombination, but \n",
    "recombination hypotheses was tested using multiple test correction\n",
    "\n",
    "explroatory PHI test with all 395 sequences p val 0.829802782906765\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Genomic recombination analysis of strain SH2016. RDP4 package strongly predicted that the\n",
    "strain SH2016 was a highly probable homologous recombinant resulting from HAdV-1 (strain: human/USA/\n",
    "VT2672/2003/1[P1H1F1], GenBank ID: JX173083) and HAdV-2 (stain: T215/Ft Jackson South Carolina\n",
    "USA/2002, GenBank ID: KX384959) with beginning breakpoint located around 28040 (without gaps) of HAdV1, within the gene coding for putative host modulation protein E3 (early E3 12.5 kDa glycoprotein) and with\n",
    "ending breakpoint located around 31067 (without gaps) of HAdV-1, within the gene coding for fber protein\n",
    "(Fig. 2B). Te similarities with possible major parent strain (HAdV-1) and minor parent strain (HAdV-2) were\n",
    "99.3% and 98.6%, respectively. Indeed, 7 algorithms (RDP, GENECONV, BootScan, MaxChi, Chimaera, SiScan,\n",
    "3Seq, LARD, PhylPro (Supplemental Figs S1–7), were utilized to predict potential recombination events between\n",
    "the input sequences) supported this event with p-values ranging from 2.347×10−187 to 2.179×10−12 (Table 4).\n",
    "Similarity plot analysis using SimPlot sofware were performed to confrm the consequent of recombination\n",
    "events within the genome of SH2016. As well as, SimPlot analysis indicated that the mosaic structure comprised\n",
    "of the SH2016 genome originated not only from mainly circulating viral strain: prototype HAdV-1 basically,\n",
    "but also from a small quantity of HAdV-2 (Fig. 2C). Te results coincided with phylogenetic analyses, which\n",
    "indicated that both of the lef region of recombinant point (5′-end, 1–28039) and the right region of recombinant\n",
    "point (3′-end, 31067–35946) of SH2016 strain were clustered into HAdV-1 group with high confdence (bootstrap\n",
    "value=100% or 97%, Fig. 3A,B), but the recombinant region was clustered into HAdV-2/6/57 group (bootstrap\n",
    "value=100%, Fig. 3C). So these fndings re-confrmed that SH2016 appeared from potential genetic recombination events, which HAdV-1, and HAdV-2 participated in this process.\n",
    "\n",
    "Recombination is a rare event in HTLV-1\n",
    "previously philippe alphonso (2019) reported evidence of recombinantion of HTLV-1 strains in the 3' LTR segmnent in subjects from in Africa, suggesting circulation of \n",
    "\n",
    "Done with 7 breakpoint analysis.\n",
    "\n",
    "    Best break point locations: 1325, 4506, 6641, 7373, 7389, 8628, 8969\n",
    "\n",
    "    c-AIC = 33544.63060858713\n",
    "\n",
    "    AH was deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "\n",
    "#Get genomes in Fasta and metadata from a list\n",
    "datasets download virus genome accession --inputfile list.txt\n",
    "dataformat tsv virus-genome --package /home/dev105/OneDrive/phyloseq0919/data/seq_raw/ncbi_seq/Raw_HTLV_1only/ncbi_dataset.zip > dataformat.tsv\n",
    "\n",
    "#filtering \n",
    "cd /home/dev105/OneDrive/phyloseq0919/data/seq_raw/ncbi_seq/Raw_HTLV_1only\n",
    "cat list328fastncbi.fa | seqkit grep -r -p M86840.1 -p LC378575.1 -p L03562.2 -p L03561.2 -p D13784.1 -p AB979451.1 -v > seqkit_ncbifilteredseq_1124.fa\n",
    "#to check\n",
    "grep -A1 -i M86840.1 seqkit_ncbifilteredseq_1124.fa\n",
    "\n",
    "#remove descriptions after space\n",
    "awk -F \"|\" '/^>/ {print $1;next}1' file.fa > simplenames.fa\n",
    "awk sub{/.*Nakahata_/,\"Peru\",\"_\",$NF;}1'\n",
    "#remove all letter after space\n",
    "sed '/^>/ s/ .*//'\n",
    "#to add the >:\n",
    "sed 's/Peru/\\>Peru/g' cgperu1.fa >cgperu2.fa\n",
    "seqkit replace -p \"\\s.+\" seqkit_ncbifilteredseq_1124.fa > seqkit_ncbifiltered_nodesc_1124.fasta\n",
    "\n",
    "#remove duplicates (no duplicates in this case)\n",
    "seqkit rmdup -s seqkit_ncbifiltered_nodesc_1124.fasta > seqkit_wodup_filtered_1124.fa -d otro.fa\n",
    "\n",
    "#remove N on the sequences (not necessay yet)\n",
    "awk '!/^>/{gsub(/[^CTAG]/, \"-\")}1'\n",
    "seqkit seq -g seqkit_ncbifiltered_nodesc_1124.fasta > seqkit_nfilt_nodesc_nonn_11.24.fasta\n",
    "\n",
    "# count number of sequences in original peru file\n",
    "grep \">\" file.fasta | wc -l\n",
    "\n",
    "# change the names (erase Peru_ or Japan_)\n",
    "sed 's/\\>Peru_/\\>/g'\n",
    "sed 's/>Peru_ivar_/>/g' totalivar.fa > peru_shortfasta.fa\n",
    "sed 's/>Japan_ivar_/>JP_/g' peru_shortfasta.fa >shortfasta.fa\n",
    "sed 's/>SS/>PE_SS/g' shortfasta.fa >shortfinalunfiltered.fa\n",
    "\n",
    "# replace NN by - (noyet)\n",
    "awk '!/^>/{gsub(/[^CTAG]/, \"-\")}1' shortfinal.fasta > shortwithoutN.fa\n",
    "#filter sequences by name (less than 6000)\n",
    "cat | seqkit grep -r -p IRID011_S130 -p IRID038_S122 -p IRID040_S124 -p IRID067_S233 -p JP_14_S84 -p JP_17_S87 -v > seqkit_perufiltered_1124.fa\n",
    "#remove duplicates by sequence\n",
    "seqkit rmdup -s seqkit_perufiltered_1124.fa > seqkit_wodup_filtered_1124.fa -d otro.fa\n",
    "#create a preliminary list\n",
    "grep -e \">\" seqkit_wodup_filtered_1124.fa |wc -l\n",
    "# seqkit_ncbifiltered_nodesc_1124.fasta (final file with N)\n",
    "\n",
    "#join two files /home/dev105/OneDrive/phyloseq0919/data/mature_data\n",
    "#cat seqkit_nfilt_nodesc_nonn_11.24.fasta seqkit_wodup_filtered_1124.fa >final_filtered_woduplicates_1124.fa\n",
    "cd /home/dev105/OneDrive/phyloseq0919/data/mature_data\n",
    "mafft --6merpair --thread -4 --keeplength  final_filtered_woduplicates_1124.fa /home/dev105/OneDrive/phyloseq0919/refgenome_HTLV/J2029/J02029.1.fasta\n",
    " > final_fil1_dup0_1124.fa\n",
    "\n",
    "\n",
    " #aalignment\n",
    "mafft --6merpair --localpair --maxiterate 1000 --thread 4 --keeplength --addfragments final_filtered_woduplicates_1124.fasta /home/dev105/OneDrive/phyloseq0919/refgenome_HTLV/J2029/J02029.1.fasta > final\n",
    "# trimming manually 22 and 13 nucleotides at both ends (aliview)\n",
    "/home/dev105/OneDrive/phyloseq0919/data/mature_data/final_mafft1_filt1_wodup1_gap1_1124.fasta\n",
    "#new duplicates appeared\n",
    "seqkit rmdup -s final_mafft1_filt1_wodup1_gap1_1124.fasta > seqkit_mafft1_filt1_wodup1_gap1_dup0_1124.fasta -d duplicates.fa\n",
    "grep \">\" duplicates.fa\n",
    "#395 sequences remain\n",
    "grep -e \">\" seqkit_mafft1_filt1_wodup1_gap1_dup0_1124.fasta | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 09-19 rxaml\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "cat maffted/seqkit_mafft1_filt1_wodup1_gap1_dup0_1124.fasta | seqkit grep -r -p KF797883.1 -p KY007245.1 -p KY007246.1  -v > seqkit_norecomb_1201.fasta\n",
    "remains 392\n",
    "#an additional list for simplot y GARD\n",
    "cat maffted/seqkit_mafft1_filt1_wodup1_gap1_dup0_1124.fasta | seqkit grep -r -p KF797883.1 -p KY007245.1 -p KY007246.1 -p KF797833.1 -p KY007272.1 -p KY007262.1 -p KY007253.1 -p KX905202.1 -p L02534.1 > recombinant_list_1201.fasta\n",
    "\n",
    "raxml-ng --all --threads 5 --bs-trees 1000 --msa-format FASTA --data-type DNA --prefix raxml_1124 --msa  seqkit_norecomb_1201.fasta --model  partition.txt --bs-cutoff 0.03 --blmin 1e-5 --outgroup \"L02534.1\",\"KX905203.1\", \"KX905202.1\", \"KF242506.1\", \"KF242505.1\", \"JX891479.1\", \"JX891478.1\"\n",
    "seqkit_norecomb_1201\n",
    "\n",
    "#Annotation\n",
    "prokka -kingdom Viruses --outdir htlv_prokka --genus Deltaretrovirus J02029.1.fasta\n",
    "\n",
    "raxml-ng --all --threads 5 --bs-trees 10000 --msa-format FASTA --data-type DNA --prefix raxml_1124 --msa  seqkit_mafft1_filt1_wodup1_gap1_dup0_1124.fasta --model  partition.txt --bs-cutoff 0.03 --blmin 1e-5 --outgroup \"L02534.1\",\"KX905203.1\", \"KX905202.1\", \"KF242506.1\", \"KF242505.1\", \"JX891479.1\", \"JX891478.1\"\n",
    "\n",
    "\n",
    "raxml-ng --bootstrap --bs-trees 1000 --msa seqkit_norecom_321_1207.fasta --model partition.txt --prefix ~/OneDrive/phyloseq0919/results/rxaml/1208_rxaml_2 --seed 5 --threads 5\n",
    "\n",
    " raxml-ng --bsconverge --bs-trees raxml_1124.raxml.bootstraps --prefix converge --seed 2 --\n",
    "threads 1 --bs-cutoff 0.01\n",
    " converge after 600\n",
    "\n",
    " raxml-ng --support --tree raxml_1124.raxml.bestTree --bs-trees raxml_1124.raxml.bootstraps --prefix 1208_support --threads 1 --seed 2 --bs-metric fbp, tbe\n",
    "\n",
    "\n",
    "raxml-ng --all --threads 5 --bs-trees 1000 --msa-format FASTA --data-type DNA --prefix raxml_1124 --msa  seqkit_norecomb_1201.fasta --model  partition.txt --bs-cutoff 0.03 --blmin 1e-5 \n",
    "\n",
    "\n",
    "#First necessary to find the right model\n",
    "#nexus\n",
    "begin sets;\n",
    "\tcharset 5LTR_3LTR = 1-755  8279-9033;\n",
    "\tcharset env_gp46_gp21 = 5181-6647\\3;\n",
    "\tcharset restHTLV = 756-5180 6648-8278;\n",
    "end;\n",
    "\n",
    "raxml-ng --all --threads 5 --bs-trees 10000 --msa-format FASTA --data-type DNA --prefix raxml_1124 --msa  seqkit_mafft1_filt1_wodup1_gap1_dup0_1124.fasta --model bestmodel_101323_CG_allpartitions.best_scheme.nex --bs-cutoff 0.03 --blmin 1e-5 \n",
    "\n",
    "#################Run 01-16 All sequences but without JP\n",
    "raxml-ng --all --threads 5 --bs-trees 1000 --msa-format FASTA --data-type DNA --prefix raxml_0116 --msa seqkit_norec_noJP_0112.fasta --model partition.txt --bs-cutoff 0.03 --blmin 1e-5\n",
    "\n",
    "\n",
    "\n",
    "#Another option is to use IQTREE\n",
    "iqtree2 -s  seqkit_mafft1_filt1_wodup1_gap1_dup0_1124.fasta  -p nexus.nex -m MF -mtree -T 5 --prefix MF_\n",
    "iqtree2 -s 0919maffted_allcases_trimmed-manual281_v2_092223.fa -p part.nex --polytomy  -blmin 1e-6 -B 10000 --prefix parti_ -T 4\n",
    "iqtree2 -s 0919maffted_allcases_trimmed-manual281_v2_092223.fa -p part.nex --polytomy  -blmin 3.3e-7 -B 10000 --prefix parti_ -T 4\n",
    "find the best model for gp46\n",
    "iqtree2 -s (sequences o dir) -p (partition) -m (modelo) -B 1000 -alrt 1000 -T 5\n",
    "m MF+MERGE find the best partition scheme\n",
    "--sampling GENESITE\n",
    "iqtree2 -s 0923gp46all_2020liao.fa -m TN+F+I+R2 -B 1000 -alrt 1000 --polytomy  -blmin 3.3e-7 -T 5  -prefix gp46tree_\n",
    "iqtree2 -s 0923gp46all_2020liao.fa -m TN+F+I+R2 -B 10000 -alrt 10000 --polytomy  -blmin 3.3e-7 -T 5  --prefix gp46tree\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
